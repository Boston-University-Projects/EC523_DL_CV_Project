{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.google_utils import attempt_load\n",
    "from utils.datasets import create_dataloader\n",
    "from utils.general import coco80_to_coco91_class, check_dataset, check_file, check_img_size, box_iou, \\\n",
    "    non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, clip_coords, set_logging, increment_path\n",
    "from utils.loss import compute_loss\n",
    "from utils.metrics import ap_per_class\n",
    "from utils.plots import plot_images, output_to_target\n",
    "from utils.torch_utils import select_device, time_synchronized\n",
    "\n",
    "from models.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_classes(path):\n",
    "    # Loads *.names file at 'path'\n",
    "    with open(path, 'r') as f:\n",
    "        names = f.read().split('\\n')\n",
    "    return list(filter(None, names))  # filter removes empty strings (such as last line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: test.py --conf-thres 0.5 --img 416 --batch 32 --device cpu --data zero-waste-1/data.yaml --cfg yolor/cfg/yolor_p6.cfg --weights \"runs/train/yolor_p6_2022_04_05-19_58_08/weights/best_overall.pt\" --task test --names yolor/data/zerowaste.names --verbose --save-json --save-conf\n",
      "       [-h] [--weights WEIGHTS [WEIGHTS ...]] [--data DATA]\n",
      "       [--batch-size BATCH_SIZE] [--img-size IMG_SIZE]\n",
      "       [--conf-thres CONF_THRES] [--iou-thres IOU_THRES] [--task TASK]\n",
      "       [--device DEVICE] [--single-cls] [--augment] [--verbose] [--save-txt]\n",
      "       [--save-conf] [--save-json] [--project PROJECT] [--name NAME]\n",
      "       [--exist-ok] [--cfg CFG] [--names NAMES]\n",
      "test.py --conf-thres 0.5 --img 416 --batch 32 --device cpu --data zero-waste-1/data.yaml --cfg yolor/cfg/yolor_p6.cfg --weights \"runs/train/yolor_p6_2022_04_05-19_58_08/weights/best_overall.pt\" --task test --names yolor/data/zerowaste.names --verbose --save-json --save-conf: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"d0e3ebc8-665b-44b0-a779-1456f0803eb0\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/scratch/tmp-241706ccLdi7q70jN.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(prog='test.py --conf-thres 0.5 --img 416 --batch 32 --device cpu --data zero-waste-1/data.yaml --cfg yolor/cfg/yolor_p6.cfg --weights \"runs/train/yolor_p6_2022_04_05-19_58_08/weights/best_overall.pt\" --task test --names yolor/data/zerowaste.names --verbose --save-json --save-conf')\n",
    "parser.add_argument('--weights', nargs='+', type=str, default=\"../runs/train/yolor_p6_2022_04_05-19_58_08/weights/best_overall.pt\", help='model.pt path(s)')\n",
    "parser.add_argument('--data', type=str, default=\"../zero-waste-1/data.yaml\", help='*.data path')\n",
    "parser.add_argument('--batch-size', type=int, default=32, help='size of each image batch')\n",
    "parser.add_argument('--img-size', type=int, default=448, help='inference size (pixels)')\n",
    "parser.add_argument('--conf-thres', type=float, default=0.5, help='object confidence threshold')\n",
    "parser.add_argument('--iou-thres', type=float, default=0.65, help='IOU threshold for NMS')\n",
    "parser.add_argument('--task', default='test', help=\"'val', 'test', 'study'\")\n",
    "parser.add_argument('--device', default='cpu', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "parser.add_argument('--single-cls', action='store_true', help='treat as single-class dataset')\n",
    "parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
    "parser.add_argument('--verbose', default='True', action='store_true', help='report mAP by class')\n",
    "parser.add_argument('--save-txt',  action='store_true', help='save results to *.txt')\n",
    "parser.add_argument('--save-conf', default='True', action='store_true', help='save confidences in --save-txt labels')\n",
    "parser.add_argument('--save-json', default='True',action='store_true', help='save a cocoapi-compatible JSON results file')\n",
    "parser.add_argument('--project', default='runs/test', help='save to project/name')\n",
    "parser.add_argument('--name', default='exp', help='save to project/name')\n",
    "parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
    "parser.add_argument('--cfg', type=str, default='cfg/yolor_p6.cfg', help='*.cfg path')\n",
    "parser.add_argument('--names', type=str, default='data/zerowaste.names', help='*.cfg path')\n",
    "opt = parser.parse_args()\n",
    "opt.save_json |= opt.data.endswith('coco.yaml')\n",
    "opt.data = check_file(opt.data)  # check file\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"../zero-waste-1/data.yaml\"\n",
    "weights=\"../runs/train/yolor_p6_2022_04_05-19_58_08/weights/best_overall.pt\",\n",
    "batch_size=16,\n",
    "imgsz=640,\n",
    "conf_thres=0.5,\n",
    "iou_thres=0.6,  # for NMS\n",
    "save_json=True,\n",
    "single_cls=False,\n",
    "augment=False,\n",
    "verbose=True,\n",
    "model=None,\n",
    "dataloader=None,\n",
    "save_dir=Path(''),  # for saving images\n",
    "save_txt=False,  # for auto-labelling\n",
    "save_conf=False,\n",
    "plots=True,\n",
    "log_imgs=0  # number of logged images\n",
    "task = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "opt = Namespace(augment=False, batch_size=32, cfg='./cfg/yolor_p6.cfg', conf_thres=0.5, data='../zero-waste-1/data.yaml', device='cpu', exist_ok=False, img_size=416, iou_thres=0.65, name='exp', names='./data/zerowaste.names', project='../runs/test', save_conf=True, save_json=True, save_txt=False, single_cls=False, task='test', verbose=True, weights=['../runs/train/yolor_p6_2022_04_05-19_58_08/weights/best_overall.pt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment=False\n",
    "batch_size=32\n",
    "cfg='cfg/yolor_p6.cfg'\n",
    "conf_thres=0.5\n",
    "data='../zero-waste-1/data.yaml'\n",
    "device='cpu'\n",
    "exist_ok=False\n",
    "img_size=416\n",
    "iou_thres=0.65\n",
    "name='exp'\n",
    "names='data/zerowaste.names'\n",
    "project='../runs/test'\n",
    "save_conf=True\n",
    "save_json=True\n",
    "save_txt=False\n",
    "single_cls=False\n",
    "task='test'\n",
    "verbose=True\n",
    "weights=['../runs/train/yolor_p6_2022_03_26-10_44_07/weights/best_overall.pt']\n",
    "imgsz=448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using torch 1.9.0+cu111 CPU\n",
      "\n",
      "Model Summary: 665 layers, 36854616 parameters, 36854616 gradients, 80.410315000 GFLOPS\n"
     ]
    }
   ],
   "source": [
    "set_logging()\n",
    "device = select_device(opt.device, batch_size=batch_size)\n",
    "save_txt = opt.save_txt  # save *.txt labels\n",
    "\n",
    "# Directories: where all the logging file will be saved for this experiment\n",
    "save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run\n",
    "(save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "# Load model\n",
    "model = Darknet(opt.cfg).to(device)\n",
    "try:\n",
    "    ckpt = torch.load(weights[0], map_location=device)  # load checkpoint\n",
    "    ckpt['model'] = {k: v for k, v in ckpt['model'].items() if model.state_dict()[k].numel() == v.numel()}\n",
    "    model.load_state_dict(ckpt['model'], strict=False)\n",
    "except:\n",
    "    load_darknet_weights(model, weights[0])\n",
    "imgsz = check_img_size(imgsz, s=64)  # check img_size\n",
    "\n",
    "# Half: half precision if we are running on GPU\n",
    "half = device.type != 'cpu'\n",
    "if half:\n",
    "    model.half()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projectnb2/dl523/students/dong760/roboflow-ai/yolor\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "yaml_dir='/projectnb2/dl523/students/dong760/roboflow-ai/zero-waste-1/data.yaml'\n",
    "model.eval()\n",
    "is_coco = yaml_dir.endswith('coco.yaml')  # is COCO dataset\n",
    "with open(yaml_dir) as f:\n",
    "    data = yaml.load(f, Loader=yaml.FullLoader)  # model dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': ['cardboard', 'metal', 'rigid_plastic', 'soft_plastic'],\n",
       " 'nc': 4,\n",
       " 'train': '/projectnb2/dl523/students/dong760/roboflow-ai/zero-waste-1/train/images',\n",
       " 'val': '/projectnb2/dl523/students/dong760/roboflow-ai/zero-waste-1/valid/images',\n",
       " 'test': '/projectnb2/dl523/students/dong760/roboflow-ai/zero-waste-1/test/images'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dataset(data)  # check\n",
    "nc = 1 if single_cls else int(data['nc'])  # number of classes\n",
    "iouv = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95\n",
    "niou = iouv.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_3916/3700222460.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlog_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwandb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# ceil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m  \u001b[0;31m# Weights & Biases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "# Logging\n",
    "log_imgs, wandb = min(log_imgs, 100), None  # ceil\n",
    "try:\n",
    "    import wandb  # Weights & Biases\n",
    "except ImportError:\n",
    "    log_imgs = 0\n",
    "\n",
    "# Dataloader\n",
    "img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n",
    "_ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n",
    "path = data['test'] if task == 'test' else data['val']  # path to val/test images\n",
    "dataloader = create_dataloader(path, imgsz, batch_size, 64, opt, pad=0.5, rect=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_json = glob.glob(\"/projectnb/dl523/students/dong760/roboflow-ai/test/_annotations.coco.json\")[0]\n",
    "# importing the module\n",
    "pred_json = \"../runs/test/exp43/best_overall_predictions.json\"\n",
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f1 = open(anno_json)\n",
    "f2 = open(pred_json)\n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "gT_dict = json.load(f1)\n",
    "jdict = json.load(f2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converer_dict = gT_dict[\"images\"]\n",
    "suffix = converer_dict[0][\"file_name\"].split('.')[-1]\n",
    "for i in range(len(jdict)):\n",
    "    image_id = jdict[i]['image_id'] + \".\" + suffix\n",
    "    if not image_id.isnumeric():\n",
    "        flag = True # Mark as incorrect image_id\n",
    "    for item in converer_dict:\n",
    "        # If we found a match, and the current image_id is marked as incorrect format ==> We will correct it\n",
    "        if flag and image_id == item[\"file_name\"]:\n",
    "            print(f\"jdict[i]['image_id']: {jdict[i]['image_id']}, item['id']: {item['id']}\")\n",
    "            jdict[i]['image_id'] = item['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'08_frame_011500_PNG.rf.fa2aa81dc2839b709ca7ce5e9feeed9b'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jdict[1][\"image_id\"].isnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jpg'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "converer_dict[428][\"file_name\"].split('.')[-1]\n",
    "# for item in converer_dict:\n",
    "#     # If we found a match, and the current image_id is marked as incorrect format ==> We will correct it\n",
    "#     if flag and image_id == item[\"file_name\"]:\n",
    "#         jdict[i][\"image_id\"] = item[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.22s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.45s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.11s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "================> Start Printing evaluated result:\n",
      "[          0           0           0           0           0           0           0           0           0           0           0           0]\n",
      "================> End of Printing!\n"
     ]
    }
   ],
   "source": [
    "pred_json = \"../runs/test/exp51/best_overall_predictions.json\"\n",
    "# anno_json = glob.glob(\"coco/annotations/instances_val*.json\")[0]  \n",
    "anno_json = glob.glob(\"/projectnb2/dl523/students/dong760/zerowaste_dataset/zerowaste-f-final/test/labels.json\")[0]  # finding the annotations json \n",
    "# anno_json = glob.glob(\"/projectnb/dl523/students/dong760/roboflow-ai/test/_annotations.coco.json\")[0]  # finding the annotations json \n",
    "is_coco = False\n",
    "try:  # https://github.com/cocodataset/cocoapi/blob/master/PythonAPIpycocoEvalDemo.ipynb\n",
    "    from pycocotools.coco import COCO\n",
    "    from pycocotools.cocoeval import COCOeval\n",
    "    anno = COCO(anno_json)  # init annotations api\n",
    "    pred = anno.loadRes(pred_json)  # init predictions api\n",
    "    # imgIds=sorted(anno.getImgIds())\n",
    "    # imgIds=imgIds[0:100]\n",
    "    # imgId = imgIds[np.random.randint(100)]\n",
    "    eval = COCOeval(anno, pred, 'bbox')\n",
    "    if is_coco:\n",
    "        eval.params.imgIds = [int(Path(x).stem) for x in dataloader.dataset.img_files]  # image IDs to evaluate\n",
    "    eval.evaluate()\n",
    "    eval.accumulate()\n",
    "    eval.summarize()\n",
    "    map, map50 = eval.stats[:2]  # update results (mAP@0.5:0.95, mAP@0.5)\n",
    "    print(\"================> Start Printing evaluated result:\")\n",
    "    print(eval.stats)\n",
    "    print(\"================> End of Printing!\")\n",
    "except Exception as e:\n",
    "    print('ERROR: pycocotools unable to run: %s' % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno.getCatIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=8.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "#initialize COCO ground truth api\n",
    "dataDir='../'\n",
    "dataType='val2014'\n",
    "annFile = '%s/annotations/%s_%s.json'%(dataDir,prefix,dataType)\n",
    "cocoGt=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...     \n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "#initialize COCO detections api\n",
    "resFile='%s/results/%s_%s_fake%s100_results.json'\n",
    "resFile = resFile%(dataDir, prefix, dataType, annType)\n",
    "cocoDt=cocoGt.loadRes(resFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgIds=sorted(cocoGt.getImgIds())\n",
    "imgIds=imgIds[0:100]\n",
    "imgId = imgIds[np.random.randint(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...      \n",
      "DONE (t=0.46s).\n",
      "Accumulating evaluation results...   \n",
      "DONE (t=0.38s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.505\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.697\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.573\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.586\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.501\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.594\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.595\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.640\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.566\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.564\n"
     ]
    }
   ],
   "source": [
    "# running evaluation\n",
    "cocoEval = COCOeval(cocoGt,cocoDt,annType)\n",
    "cocoEval.params.imgIds  = imgIds\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca0b83cf779738b65c72b916252aecc4e56a1a3d2993a7c32a45f1b5451d7c5a"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
